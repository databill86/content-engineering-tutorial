{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword Deduping\n",
    "\n",
    "This is part of cleaning up the keywords, we want to dedupe keywords that are really close to each other, such as plural and singular versions of the same thing, so they don't show up as facets together. For that, we will use the [simhash algorithm](https://moz.com/devblog/near-duplicate-detection/) via the [simhash-py](https://github.com/seomoz/simhash-py) module to find near-duplicate keywords and normalize them for purposes of loading up the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import simhash\n",
    "\n",
    "from nltk.metrics.distance import edit_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data\"\n",
    "\n",
    "MERGED_KEYWORDS = os.path.join(DATA_DIR, \"raw_keywords.txt\")\n",
    "NEAR_DUPS = os.path.join(DATA_DIR, \"keyword_neardup_mappings.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hash(s):\n",
    "    shingles = [\"\".join(s) for s in simhash.shingle(s, window=3)]\n",
    "    hashes = []\n",
    "    for shingle in shingles:\n",
    "        hashes.append(simhash.unsigned_hash(shingle))\n",
    "    return simhash.compute(hashes)\n",
    "\n",
    "\n",
    "hashes = []\n",
    "hash2keyword = {}\n",
    "fmrgk = open(MERGED_KEYWORDS, \"r\")\n",
    "for line in fmrgk:\n",
    "    keyword = line.strip()\n",
    "    hash_val = create_hash(keyword)\n",
    "    hashes.append(hash_val)\n",
    "    hash2keyword[hash_val] = keyword\n",
    "fmrgk.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of bits that may differ in matching pairs\n",
    "distance = 10\n",
    "# Number of blocks to use (more in the next section)\n",
    "blocks = distance + 1\n",
    "matches = simhash.find_all(hashes, blocks, distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of mappings: 259\n"
     ]
    }
   ],
   "source": [
    "fndm = open(NEAR_DUPS, \"w\")\n",
    "num_mappings = 0\n",
    "for lhs, rhs in matches:\n",
    "    lhs_keyword = hash2keyword[lhs]\n",
    "    rhs_keyword = hash2keyword[rhs]\n",
    "    if edit_distance(lhs_keyword, rhs_keyword) > 2:\n",
    "        continue\n",
    "    len_lhs = len(lhs_keyword)\n",
    "    len_rhs = len(rhs_keyword)\n",
    "    if len_lhs < len_rhs:\n",
    "        fndm.write(\"{:s}\\t{:s}\\n\".format(rhs_keyword, lhs_keyword))\n",
    "    else:\n",
    "        fndm.write(\"{:s}\\t{:s}\\n\".format(lhs_keyword, rhs_keyword))\n",
    "    num_mappings += 1\n",
    "    \n",
    "fndm.close()\n",
    "print(\"number of mappings: {:d}\".format(num_mappings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Parsing using Py-AhoCorasick\n",
    "\n",
    "We want to parse out keywords from the text and weight them higher in our query. Since our number of keywords are fairly small, we will use an in-memory trie supplied by the py-AhoCorasick library to parse each query as it comes in, and construct a query which contains these keywords as multi-word phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ahocorasick\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data\"\n",
    "\n",
    "CURATED_KEYWORDS = os.path.join(DATA_DIR, \"raw_keywords.txt\")\n",
    "\n",
    "KEYWORD_NEARDUP_MAPPINGS = os.path.join(DATA_DIR, \"keyword_neardup_mappings.tsv\")\n",
    "KEYWORD_DEDUPE_MAPPINGS = os.path.join(DATA_DIR, \"keyword_dedupe_mappings.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2282 keywords loaded\n"
     ]
    }
   ],
   "source": [
    "keywords = set()\n",
    "# load from curated list\n",
    "with open(CURATED_KEYWORDS, \"r\") as fcurated:\n",
    "    for line in fcurated:\n",
    "        keywords.add(line.strip().lower())\n",
    "# load from near dup mappings\n",
    "with open(KEYWORD_NEARDUP_MAPPINGS, \"r\") as fneardup:\n",
    "    for line in fneardup:\n",
    "        kleft, kright = line.strip().lower().split(\"\\t\")\n",
    "        keywords.add(kleft)\n",
    "        keywords.add(kright)\n",
    "# load from dedupe mappings\n",
    "with open(KEYWORD_DEDUPE_MAPPINGS, \"r\") as fdedupe:\n",
    "    for line in fdedupe:\n",
    "        kleft, kright, _ = line.strip().lower().split(\"\\t\")\n",
    "        keywords.add(kleft)\n",
    "        keywords.add(kright)\n",
    "\n",
    "keywords_list = list(keywords)\n",
    "print(\"{:d} keywords loaded\".format(len(keywords_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = ahocorasick.Automaton()\n",
    "for idx, keyword in enumerate(keywords_list):\n",
    "    A.add_word(keyword, (idx, keyword))\n",
    "A.make_automaton()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neural net', 'neural network', 'neural networks', 'attention mechanism']\n"
     ]
    }
   ],
   "source": [
    "query = \"neural networks with attention mechanism\"\n",
    "phrases = [item[1][1] for item in A.iter(query)]\n",
    "print(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(title:\"neural networks with attention mechanism\"^5 title:\"neural net\"^2 title:\"neural network\"^2 title:\"neural networks\"^2 title:\"attention mechanism\"^2)^10 (abstract:\"neural networks with attention mechanism\"^5 abstract:\"neural net\"^2 abstract:\"neural network\"^2 abstract:\"neural networks\"^2 abstract:\"attention mechanism\"^2)^5 (text:\"neural networks with attention mechanism\"^5 text:\"neural net\"^2 text:\"neural network\"^2 text:\"neural networks\"^2 text:\"attention mechanism\"^2)^1\n"
     ]
    }
   ],
   "source": [
    "clauses = []\n",
    "query_fields = [\"title\", \"abstract\", \"text\"]\n",
    "query_field_boosts = [10, 5, 1]\n",
    "for query_field, boost in zip(query_fields, query_field_boosts):\n",
    "    query_field_clause = []\n",
    "    # entire input query, highest boost\n",
    "    query_field_clause.append(\"{:s}:\\\"{:s}\\\"^5\".format(query_field, query))\n",
    "    # each phrase is boosted to an intermediate boost\n",
    "    for phrase in phrases:\n",
    "        query_field_clause.append(\"{:s}:\\\"{:s}\\\"^2\".format(query_field, phrase))\n",
    "#     # each word of query (optional)\n",
    "#     for word in query.split(\" \"):\n",
    "#         query_field_clause.append(\"{:s}:{:s}\".format(query_field, word))\n",
    "    # join the field and boost it\n",
    "    clauses.append(\"({:s})^{:d}\".format(\" \".join(query_field_clause), boost))\n",
    "print(\" \".join(clauses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
